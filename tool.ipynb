{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import time\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference onnx model with DML \n",
    "> onnxruntime-directml needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "import onnx\n",
    "model_path = r\"C:\\Users\\GAME\\Documents\\Project\\Adobe\\model_rename\\Adobe-Lr_dn_bayerlinear_mgnet704.onnx\"\n",
    "model = onnx.load(model_path)   \n",
    "data_dic = {}\n",
    "def switch_case(input_datatype):\n",
    "    if input_datatype == \"FLOAT16\":\n",
    "        return np.float16\n",
    "    if input_datatype == \"FLOAT32\":\n",
    "        return np.float32\n",
    "for _input in model.graph.input:\n",
    "    input_name = _input.name\n",
    "    input_datatype = onnx.TensorProto.DataType.Name( _input.type.tensor_type.elem_type)\n",
    "    input_shape = [int(dim.dim_value) for dim in _input.type.tensor_type.shape.dim] \n",
    "    np_dataype = switch_case(input_datatype)\n",
    "    input_data = np.random.randn(*input_shape).astype(np_dataype) # The * before the shape variable is used to unpack the values from the shape list \n",
    "    data_dic[input_name] = input_data\n",
    "\n",
    "sess_options = ort.SessionOptions()\n",
    "providers = [\"DmlExecutionProvider\"]\n",
    "sess = ort.InferenceSession(model_path, sess_options=sess_options,providers=providers)\n",
    "output = sess.run(None, data_dic)\n",
    "print(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map Adobe model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_file = \"model_mapping.txt\"\n",
    "line_count = 0\n",
    "dict_name={}\n",
    "with open(mapping_file, \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        line_count+=1\n",
    "        if line_count == 1:\n",
    "            continue\n",
    "        a,b=line.rstrip().split(\"\t\")\n",
    "        dict_name[b] = a\n",
    "\n",
    "print(dict_name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all onnx model\n",
    "import os\n",
    "import shutil\n",
    "# Provide the directory path\n",
    "directory = r\"Adobe_models\\Adobe_models\\AI_Model_Restricted\"\n",
    "new_directory = r\"model_rename\"\n",
    "# Traverse through the directory\n",
    "for root, dirs, files in os.walk(directory):\n",
    "    \n",
    "    for file in files:\n",
    "        # Print the file name\n",
    "        key = file.split(\".onnx\")[0] \n",
    "        if key in dict_name.keys():\n",
    "\n",
    "            target_path = os.path.join(new_directory, dict_name[key]+\".onnx\")\n",
    "            source_path = os.path.join(root,file)\n",
    "            if not os.path.exists(source_path):\n",
    "                print(source_path)\n",
    "                continue\n",
    "            shutil.copy2(source_path, target_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract DDI info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "ddi_root= r\"C:\\Intel\\igfx\\d3d12\"\n",
    "new_root= r\"C:\\Users\\GAME\\Documents\\Project\\Adobe\\analyze\\ddilog_backup\"\n",
    "modelfile = glob.glob(r\"C:\\Users\\GAME\\Documents\\Project\\Adobe\\model_rename\\*.onnx\")\n",
    "#print(modelfile)\n",
    "for i in range(45):\n",
    "        ddi_file = str(i+1)+\".log\"\n",
    "        print(os.path.basename(modelfile[i]))\n",
    "        modelname = os.path.basename(modelfile[i]).split(\".onnx\")[0]\n",
    "        source_path = os.path.join(ddi_root, ddi_file)\n",
    "        target_path = os.path.join(new_root, modelname+\".log\")\n",
    "        if not os.path.exists(source_path):\n",
    "            print(source_path)\n",
    "            continue\n",
    "        shutil.copy(source_path, target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "input_string = \"Input = [0x1,0x200,0x80,0x80], Filter = [0x200,0x200,0x3,0x3], Bias = [0x1,0x200,0x1,0x1], Output = [0x1,0x200,0x80,0x80]\"\n",
    "input_string = \"Input = [0x1,0x3,0x400,0x400], Filter = [0x80,0x3,0x3,0x3], Bias = [0x1,0x80,0x1,0x1], Output = [0x1,0x80,0x400,0x400]\"\n",
    "values = re.findall(r'0x\\w+', input_string)\n",
    "output = []\n",
    "for idx, val in enumerate(values):\n",
    "    output.append(int(val, 16))\n",
    "\n",
    "print(\"input \", output[:4])\n",
    "print(\"filter\", output[4:8])\n",
    "print(\"bias  \", output[8:12])\n",
    "print(\"output\", output[12:16])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse ddi log into json file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import csv\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def create_ddiConv_json(root_path,filename):\n",
    "    ddi_file = os.path.join(root_path, filename)\n",
    "    json_file = os.path.join(root_path, filename.replace(\"log\",\"json\"))\n",
    "    dic ={}\n",
    "    openf =  open(ddi_file, \"r\")\n",
    "\n",
    "    lines = openf.readlines()\n",
    "    #print(len(lines))\n",
    "    i = -1\n",
    "    while i < len(lines)-1:\n",
    "        i+=1\n",
    "        if \"Passed-Metacommand type : Convolution1\" in lines[i]:\n",
    "            #print(lines[i-12:i])\n",
    "            mc_type = lines[i].rstrip().split(\"type :\")[-1]\n",
    "            \n",
    "            kernel_name_idx = -1\n",
    "            for k in range(11):\n",
    "                if \"Conv Kernel:\" in lines[i-k]:\n",
    "                    kernel_name_idx = i-k\n",
    "                    # print(lines[kernel_name_idx])\n",
    "                    # print(kernel_name_idx)\n",
    "                    break\n",
    "                if k == 10:\n",
    "                    assert(\"no conv kernel\")\n",
    "\n",
    "            kernel_name = lines[kernel_name_idx].rstrip().split(\"Kernel:\")[-1]\n",
    "            #print(mc_type, kernel_name)\n",
    "            if mc_type not in dic.keys():\n",
    "                dic[mc_type] = {}\n",
    "            if kernel_name not in dic[mc_type].keys():\n",
    "                dic[mc_type][kernel_name] = []\n",
    "            \n",
    "            layout_idx = -1\n",
    "            dim_idx = -1\n",
    "            param_str = []\n",
    "            for k in range(6):\n",
    "                dim_idx = kernel_name_idx-k\n",
    "                layout_idx = kernel_name_idx - k+2\n",
    "                param_str =  re.findall(r'0x\\w+', lines[dim_idx])\n",
    "                if len(param_str) > 5:\n",
    "                    break\n",
    "            \n",
    "          \n",
    "            # print(dim_idx, lines[dim_idx])   \n",
    "            # print(param_str)\n",
    "            param_list = []\n",
    "            for idx, val in enumerate(param_str):\n",
    "                param_list.append(int(val, 16))\n",
    "\n",
    "            layout_str = \"\"\n",
    "            #print(lines[layout_idx].rstrip(), layout_idx,kernel_name_idx)\n",
    "            layout_str = re.findall(r'N\\w+', lines[layout_idx])\n",
    "\n",
    "            ''' some log  BiasDesc = isNull'''\n",
    "            output_shape = []\n",
    "            if \"IsNull\" in lines[i+5+38]:\n",
    "                outputdesc_idx = i+5+38+2\n",
    "                output_shape = param_list[9:13]\n",
    "            else:\n",
    "                outputdesc_idx = i+5+19+38\n",
    "                output_shape =  param_list[13:17]\n",
    "\n",
    "            input_stride = []\n",
    "            for j in range(4):\n",
    "                input_stride.append(int(lines[i+12+j].rstrip().split(\"=\")[-1],16))\n",
    "            output_stride = []\n",
    "            for j in range(4):\n",
    "                output_stride.append(int(lines[outputdesc_idx+8+j].rstrip().split(\"=\")[-1],16))\n",
    "\n",
    "            # inputpadding_list = \n",
    "            outputpadding_list = []\n",
    "            for j in range(5):\n",
    "                outputpadding_list.append(lines[outputdesc_idx+35+j].rstrip().split(\"=\")[-1])\n",
    " \n",
    "            filter_stride = []\n",
    "            for j in range(3):\n",
    "                filter_stride.append(int(lines[outputdesc_idx+22+j].rstrip().split(\"=\")[-1],16))\n",
    "\n",
    "            filter_dilation =  []\n",
    "            for j in range(3):\n",
    "                filter_dilation.append(int(lines[outputdesc_idx+25+j].rstrip().split(\"=\")[-1],16))\n",
    "            \n",
    "            input_padding = []\n",
    "            for j in range(6):\n",
    "                input_padding.append(int(lines[outputdesc_idx+28+j].rstrip().split(\"=\")[-1],16))\n",
    "            \n",
    "\n",
    "            \n",
    "            group_count =int( re.findall(r'0x\\w+', lines[outputdesc_idx+40])[0],16)\n",
    "            info_dic ={}\n",
    "            info_dic[\"input\"] = {\"shape\": param_list[1:5], \"layout\": layout_str[0], \"datatype\": re.findall(r'\\((.*?)\\)', lines[i+5])[0], \"flag\": re.findall(r'\\((.*?)\\)', lines[i+6])[0], \"stride\": input_stride, \"padding\": input_padding}\n",
    "            info_dic[\"filter\"] = {\"shape\": param_list[5:9], \"layout\": layout_str[1], \"datatype\": re.findall(r'\\((.*?)\\)', lines[i+5 + 19])[0],\"flag\": re.findall(r'\\((.*?)\\)', lines[i+6+19])[0],\"stirde\": filter_stride, \"dilation\":filter_dilation,  \"groupcount\": group_count}\n",
    "            info_dic[\"output\"] = {\"shape\":output_shape, \"layout\": layout_str[2], \"datatype\": re.findall(r'\\((.*?)\\)', lines[outputdesc_idx+1])[0],\"flag\":re.findall(r'\\((.*?)\\)', lines[outputdesc_idx+2])[0], \"stride\": output_stride,\"padding\":outputpadding_list}\n",
    "            info_dic[\"direction\"] = re.findall(r'\\((.*?)\\)', lines[outputdesc_idx+20])[0]\n",
    "            \n",
    "            if \"Function\" in lines[outputdesc_idx+42]:\n",
    "                info_dic[\"activation\"] =  re.findall(r'\\((.*?)\\)', lines[outputdesc_idx+42])[0]\n",
    "            else:\n",
    "                info_dic[\"activation\"] = \"isnull\"\n",
    "            dic[mc_type][kernel_name].append(info_dic)\n",
    "            \n",
    "            \n",
    "        \n",
    "\n",
    "    json_object = json.dumps(dic, indent=4)\n",
    "    with open(json_file, \"w\") as outfile:\n",
    "        outfile.write(json_object)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GEMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def create_ddiGEMM_json(root_path, basename):\n",
    "    ddi_file = os.path.join(root_path, basename)\n",
    "    json_file = os.path.join(root_path, basename.replace(\".log\",\"_gemm.json\"))\n",
    "    dic ={}\n",
    "    openf =  open(ddi_file, \"r\")\n",
    "\n",
    "    lines = openf.readlines()\n",
    "    #print(len(lines))\n",
    "    i = -1\n",
    "    while i < len(lines)-1:\n",
    "        i+=1\n",
    "        if \"Passed-Metacommand type : GEMM1\" in lines[i]:\n",
    "            info_dic ={}\n",
    "            mc_type = lines[i].rstrip().split(\"type :\")[-1]\n",
    "            kernel_name_idx = -1\n",
    "            kernel_name = \"\"\n",
    "            for k in range(7):\n",
    "                if \"Gemm Kernel:\" in lines[i-k]:\n",
    "                    kernel_name_idx = i-k\n",
    "                    kernel_name = lines[kernel_name_idx].rstrip().split(\"Kernel:\")[-1]\n",
    "                    break\n",
    "                if k == 6:\n",
    "                    kernel_name_idx = i-4\n",
    "                    kernel_name = \"unknown\"\n",
    "                    assert(\"no gemm kernel\")\n",
    "\n",
    "            #print(mc_type, kernel_name)\n",
    "            if mc_type not in dic.keys():\n",
    "                dic[mc_type] = {}\n",
    "            if kernel_name not in dic[mc_type].keys():\n",
    "                dic[mc_type][kernel_name] = []\n",
    "            \n",
    "            dim_idx = kernel_name_idx - 2\n",
    "            param_str =  re.findall(r'0x\\w+', lines[dim_idx])\n",
    "            \n",
    "            param_list = []\n",
    "            for idx, val in enumerate(param_str):\n",
    "                param_list.append(int(val, 16))\n",
    "\n",
    "            inputA_shape = param_list[3:5] # this first value is for thread id, gemm only has two dim MxK\n",
    "            inputB_shape = param_list[7:9] # K x N\n",
    "            \n",
    "            \n",
    "            outputdesc_idx = 0\n",
    "            if \"IsNull\" in lines[i + 41+ 2]:\n",
    "                outputdesc_idx = i + 41 + 4 # 4 is start from Cdes\n",
    "                info_dic[\"inputC\"] = \"isnull\"\n",
    "                output_shape = param_list[11:13]\n",
    "            else:\n",
    "                # Cdes is not null\n",
    "                outputdesc_idx = i + 41 + 21\n",
    "                info_dic[\"inputC\"] = \"not null\"\n",
    "                output_shape = param_list[15:17]\n",
    "\n",
    "            '''stride is useless '''\n",
    "            # inputA_stride = []\n",
    "            # for j in range(4):\n",
    "            #     inputA_stride.append(int(lines[i+12+j].rstrip().split(\"=\")[-1],16))\n",
    "            \n",
    "            # inputB_stride = []\n",
    "            # for j in range(4):\n",
    "            #     inputB_stride.append(int(lines[i+31+j].rstrip().split(\"=\")[-1],16))\n",
    "            #     #print(lines[i+31+j])\n",
    "\n",
    "            # output_stride = []\n",
    "            # for j in range(4):\n",
    "            #     output_stride.append(int(lines[outputdesc_idx +  8 +j].rstrip().split(\"=\")[-1],16))\n",
    "            #     #print(lines[outputdesc_idx +  8 +j])\n",
    "            \n",
    "            transA = \"false\" if int(lines[outputdesc_idx +  20].rstrip().split(\"=\")[-1],16) == 0 else \"true\"\n",
    "            transB = \"false\" if int(lines[outputdesc_idx +  21].rstrip().split(\"=\")[-1],16) ==0 else \"true\"\n",
    "            alpha = lines[outputdesc_idx +  22].rstrip().split(\"=\")[-1]\n",
    "            beta = lines[outputdesc_idx +  23].rstrip().split(\"=\")[-1]\n",
    "\n",
    "            info_dic[\"config\"] = {\"alpha\": alpha, \"beta\": beta}\n",
    "            info_dic[\"inputA\"] = {\"shape\": inputA_shape,  \"datatype\": re.findall(r'\\((.*?)\\)', lines[i+5])[0], \"flag\": re.findall(r'\\((.*?)\\)', lines[i+6])[0], \"transA\": transA}\n",
    "            info_dic[\"inputB\"] = {\"shape\": inputB_shape,  \"datatype\": re.findall(r'\\((.*?)\\)', lines[i+5+19])[0], \"flag\": re.findall(r'\\((.*?)\\)', lines[i+6 + 19])[0], \"transB\": transB}       \n",
    "            info_dic[\"output\"] = {\"shape\":output_shape,   \"datatype\": re.findall(r'\\((.*?)\\)', lines[outputdesc_idx + 1])[0], \"flag\": re.findall(r'\\((.*?)\\)', lines[outputdesc_idx + 2])[0]}\n",
    "            \n",
    "            dic[mc_type][kernel_name].append(info_dic)   \n",
    "\n",
    "    json_object = json.dumps(dic, indent=4)\n",
    "    with open(json_file, \"w\") as outfile:\n",
    "        outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def create_ddiPool_json(root_path, basename):\n",
    "    ddi_file = os.path.join(root_path, basename)\n",
    "    json_file = os.path.join(root_path, basename.replace(\".log\",\"_pool.json\"))\n",
    "    dic ={}\n",
    "    openf =  open(ddi_file, \"r\")\n",
    "\n",
    "    lines = openf.readlines()\n",
    "    #print(len(lines))\n",
    "    i = -1\n",
    "    while i < len(lines)-1:\n",
    "        i+=1\n",
    "        if \"Passed-Metacommand type : Pooling\" in lines[i]:\n",
    "            info_dic ={}\n",
    "            mc_type = lines[i].rstrip().split(\"type :\")[-1]\n",
    "            kernel_name_idx = i - 3\n",
    "\n",
    "            kernel_name = lines[kernel_name_idx].rstrip().split(\"Kernel:\")[-1] \n",
    "            kernel_name = \"unknown\" if kernel_name==\"\" else kernel_name\n",
    "            #print(mc_type, kernel_name)\n",
    "            if mc_type not in dic.keys():\n",
    "                dic[mc_type] = {}\n",
    "            if kernel_name not in dic[mc_type].keys():\n",
    "                dic[mc_type][kernel_name] = []      \n",
    "\n",
    "           \n",
    "            layout_list = re.findall(r'N\\w+', lines[i+4]) \n",
    "\n",
    "            input_shape = []\n",
    "            for j in range(4):\n",
    "                input_shape.append(int(lines[i+9+j].rstrip().split(\"=\")[-1],16))\n",
    "            '''offset is useless'''\n",
    "            # input_stride = []\n",
    "            # for j in range(4):\n",
    "            #     input_stride.append(int(lines[i+13+j].rstrip().split(\"=\")[-1],16))\n",
    "\n",
    "            outputdesc_idx = i+24\n",
    "            output_shape = []\n",
    "            for j in range(4):\n",
    "                output_shape.append(int(lines[outputdesc_idx + 4 + j].rstrip().split(\"=\")[-1],16))\n",
    "            '''offset is useless'''\n",
    "            # output_stride = []\n",
    "            # for j in range(4):\n",
    "            #     output_stride.append(int(lines[outputdesc_idx +  8 +j].rstrip().split(\"=\")[-1],16))\n",
    "            \n",
    "            available_function = [\"AvgPool\", \"L2Pool\", \"MaxPool\"]  # ref from driver code MetaCommandPoolingDnnl line62\n",
    "            pooling_function = available_function[int(lines[outputdesc_idx + 19].rstrip().split(\"=\")[-1],16)]\n",
    "            stride = []\n",
    "            for j in range(2):\n",
    "                stride.append(int(lines[outputdesc_idx +  21 +j].rstrip().split(\"=\")[-1],16))\n",
    "            \n",
    "            kernel_size = []  #WindowSize\n",
    "            for j in range(2):\n",
    "                kernel_size.append(int(lines[outputdesc_idx +  24 +j].rstrip().split(\"=\")[-1],16))\n",
    "\n",
    "            padding_size = []  #[h_begin, w_begin, h_end, w_end ]\n",
    "            for j in range(6):\n",
    "                if j == 2 or j ==5:\n",
    "                    continue\n",
    "                padding_size.append(int(lines[outputdesc_idx +  27 +j].rstrip().split(\"=\")[-1],16))    \n",
    "\n",
    "            '''m_PoolingParams.PoolingType is not kernel size'''\n",
    "            info_dic[\"input\"] = {\"layout\": layout_list[0],\"shape\": input_shape,  \"datatype\": re.findall(r'\\((.*?)\\)', lines[i+6])[0], \"flag\": re.findall(r'\\((.*?)\\)', lines[i+7])[0]}\n",
    "            info_dic[\"filter\"] = {\"shape\": kernel_size, \"stride\": stride, \"padding\": padding_size}\n",
    "            info_dic[\"pool_function\"] = pooling_function\n",
    "            info_dic[\"output\"] = {\"layout\": layout_list[1], \"shape\":output_shape,   \"datatype\": re.findall(r'\\((.*?)\\)', lines[outputdesc_idx + 1])[0], \"flag\": re.findall(r'\\((.*?)\\)', lines[outputdesc_idx + 2])[0]}\n",
    "            \n",
    "            dic[mc_type][kernel_name].append(info_dic)   \n",
    "\n",
    "    json_object = json.dumps(dic, indent=4)\n",
    "    with open(json_file, \"w\") as outfile:\n",
    "        outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "root_path = r\"C:\\Intel\\igfx\\d3d12\"\n",
    "basename = \"python0.json\"\n",
    "count = 0\n",
    "\n",
    "df = pd.read_json(os.path.join(root_path,basename))\n",
    "#print(basename)\n",
    "str_info = basename+\"\t\"\n",
    "conv =df[df.keys()[0]]\n",
    "\n",
    "for key in conv.keys():\n",
    "    print(key, len(conv[key]))\n",
    "    #for i in range(len(conv[key])):\n",
    "\n",
    "\n",
    "#print(count) \n",
    "    #print(str_info,f32_count,f16_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import glob\n",
    "\n",
    "# root_path = r\"C:\\Users\\GAME\\Documents\\Project\\Adobe\\analyze\\ddilog_full\"\n",
    "# basename = \"Adobe-Ae_FastMask_Query1024.log\"\n",
    "#create_ddi_json(root_path, basename)\n",
    "\n",
    "root_path = r\"C:\\Users\\GAME\\Documents\\Project\\Adobe\\analyze\\ddilog_full\"\n",
    "files = glob.glob(root_path+\"\\\\*.log\")\n",
    "\n",
    "for file in files:\n",
    "    basename = os.path.basename(file)\n",
    "    #print(basename)\n",
    "    create_ddiPool_json(root_path, basename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert json to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "root_path = r\"C:\\Users\\GAME\\Documents\\Project\\helpWindow\\szymon\"\n",
    "files = glob.glob(root_path+\"\\\\*.json\")\n",
    "\n",
    "csv_file = os.path.join(root_path,\"szymon.csv\")\n",
    "csvf = open(csv_file,\"w\",newline='')\n",
    "writer =csv.writer(csvf)\n",
    "line = [\"model_name\", \"kernel_name\",\"input_shape_n\",\"input_shape_c\",\"input_shape_h\",\"input_shape_w\", \"input_layout\", \"input_datatype\",\"input_flag\",\"input_padding\",\\\n",
    "        \"filter_shape_n\",\"filter_shape_c\",\"filter_shape_h\",\"filter_shape_w\", \"filter_layout\", \"filter_datatype\",\"filter_flag\", \"filter_stride_h\", \"filter_stride_w\", \"filter_stride_c\", \"filter_dilation_h\", \"filter_dilation_w\", \"filter_dilation_c\", \"filter_groupcount\",\n",
    "        \"output_shape_n\",\"output_shape_c\",\"output_shape_h\",\"output_shape_w\", \"output_layout\", \"output_datatype\",\"output_flag\", \"output_padding\", \n",
    "         \"direction\", \"activation\" ]\n",
    "writer.writerow(line)\n",
    "for file in files:\n",
    "    basename = os.path.basename(file)\n",
    "    df = pd.read_json(file)\n",
    "    conv =df[df.keys()[0]]\n",
    "    for key in conv.keys():\n",
    "        kernel_name = key\n",
    "        for i in range(len(conv[key])):\n",
    "            input_shape = conv[key][i][\"input\"][\"shape\"]\n",
    "            input_layout = conv[key][i][\"input\"][\"layout\"]\n",
    "            input_datatype = conv[key][i][\"input\"][\"datatype\"]\n",
    "            input_flag = conv[key][i][\"input\"][\"flag\"]\n",
    "            input_padding = [int(v) for v in  conv[key][i][\"input\"][\"padding\"]] \n",
    "\n",
    "            filter_shape = conv[key][i][\"filter\"][\"shape\"]\n",
    "            filter_layout = conv[key][i][\"filter\"][\"layout\"]\n",
    "            filter_datatype = conv[key][i][\"filter\"][\"datatype\"]\n",
    "            filter_flag = conv[key][i][\"filter\"][\"flag\"]\n",
    "            filter_stride = conv[key][i][\"filter\"][\"stirde\"]\n",
    "            filter_dilation = conv[key][i][\"filter\"][\"dilation\"]\n",
    "            filter_groupcount = conv[key][i][\"filter\"][\"groupcount\"]\n",
    "\n",
    "            output_shape = conv[key][i][\"output\"][\"shape\"]\n",
    "            output_layout = conv[key][i][\"output\"][\"layout\"]\n",
    "            output_datatype = conv[key][i][\"output\"][\"datatype\"]\n",
    "            output_flag = conv[key][i][\"output\"][\"flag\"]\n",
    "            output_padding = [int(v) for v in conv[key][i][\"output\"][\"padding\"]]\n",
    "\n",
    "            direction = conv[key][i][\"direction\"]\n",
    "            activation = conv[key][i][\"activation\"]\n",
    "\n",
    "            writer.writerow([basename, kernel_name, input_shape[0], input_shape[1], input_shape[2], input_shape[3], input_layout, input_datatype, input_flag,input_padding,\\\n",
    "                              filter_shape[0],filter_shape[1],filter_shape[2],filter_shape[3], filter_layout, filter_datatype, filter_flag, filter_stride[0], filter_stride[1],filter_stride[2],filter_dilation[0],filter_dilation[1],filter_dilation[2], filter_groupcount, \\\n",
    "                                output_shape[0],output_shape[1],output_shape[2],output_shape[3], output_layout, output_datatype, output_flag, output_padding,\n",
    "                                direction, activation])\n",
    "    \n",
    "csvf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GEMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "root_path = r\"C:\\Users\\GAME\\Documents\\Project\\Adobe\\analyze\\ddilog_full\"\n",
    "files = glob.glob(root_path+\"\\\\*_gemm.json\")\n",
    "\n",
    "csv_file = os.path.join(root_path,\"Adobe_GEMM.csv\")\n",
    "csvf = open(csv_file,\"w\",newline='')\n",
    "writer =csv.writer(csvf)\n",
    "line = [\"model_name\", \"kernel_name\",\"inputA_shape_M\",\"inputA_shape_K\", \"inputA_datatype\",\"inputA_flag\",\"transA\",\\\n",
    "       \"inputB_shape_K\",\"inputB_shape_N\", \"inputB_datatype\",\"inputB_flag\",\"transB\",\\\n",
    "       \"output_shape_M\",\"output_shape_N\", \"output_datatype\",\"output_flag\", \"inputC_flag\", \"alpha\",\"beta\" ]\n",
    "writer.writerow(line)\n",
    "for file in files:\n",
    "    basename = os.path.basename(file)\n",
    "    df = pd.read_json(file)\n",
    "    if len(df.keys()) == 0:\n",
    "        continue\n",
    "    #print(basename)\n",
    "    gemm =df[df.keys()[0]]\n",
    "    for key in gemm.keys():\n",
    "        kernel_name = key\n",
    "        for i in range(len(gemm[key])):\n",
    "            inputA_shape = gemm[key][i][\"inputA\"][\"shape\"]\n",
    "            inputA_datatype = gemm[key][i][\"inputA\"][\"datatype\"]\n",
    "            inputA_flag = gemm[key][i][\"inputA\"][\"flag\"]\n",
    "            transA = gemm[key][i][\"inputA\"][\"transA\"]\n",
    "\n",
    "            inputB_shape = gemm[key][i][\"inputB\"][\"shape\"]\n",
    "            inputB_datatype = gemm[key][i][\"inputB\"][\"datatype\"]\n",
    "            inputB_flag = gemm[key][i][\"inputB\"][\"flag\"]\n",
    "            transB = gemm[key][i][\"inputB\"][\"transB\"]\n",
    "\n",
    "            output_shape = gemm[key][i][\"output\"][\"shape\"]\n",
    "            output_datatype = gemm[key][i][\"output\"][\"datatype\"]\n",
    "            output_flag = gemm[key][i][\"output\"][\"flag\"]\n",
    "\n",
    "            inputC_flag = gemm[key][i][\"inputC\"]\n",
    "            alpha = gemm[key][i][\"config\"][\"alpha\"]\n",
    "            beta = gemm[key][i][\"config\"][\"beta\"]\n",
    "\n",
    "            writer.writerow([basename, kernel_name, inputA_shape[0], inputA_shape[1], inputA_datatype, inputA_flag,transA,\\\n",
    "                              inputB_shape[0], inputB_shape[1], inputB_datatype, inputB_flag,transB, \\\n",
    "                                output_shape[0],output_shape[1],output_datatype, output_flag,\\\n",
    "                                 inputC_flag,alpha, beta])\n",
    "    \n",
    "csvf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "root_path = r\"C:\\Users\\GAME\\Documents\\Project\\Adobe\\analyze\\ddilog_full\"\n",
    "files = glob.glob(root_path+\"\\\\*_pool.json\")\n",
    "\n",
    "csv_file = os.path.join(root_path,\"Adobe_Pooling.csv\")\n",
    "csvf = open(csv_file,\"w\",newline='')\n",
    "writer =csv.writer(csvf)\n",
    "# the name is mapping to https://onnx.ai/onnx/operators/onnx__MaxPool.html#maxpool\n",
    "line = [\"model_name\", \"kernel_name\",\"pool_function\", \\\n",
    "       \"input_layout\", \"input_shape_n\",\"input_shape_c\",\"input_shape_h\",\"input_shape_w\", \"input_datatype\",\"input_flag\",\\\n",
    "       \"kernel_shape_h\",\"kernel_shape_w\", \"stride_h\", \"stride_w\",\"pads\",\\\n",
    "       \"output_layout\", \"output_shape_n\",\"output_shape_c\", \"output_shape_h\",\"output_shape_w\", \"output_datatype\",\"output_flag\" ]\n",
    "writer.writerow(line)\n",
    "for file in files:\n",
    "    basename = os.path.basename(file)\n",
    "    df = pd.read_json(file)\n",
    "    if len(df.keys()) == 0:\n",
    "        continue\n",
    "    #print(basename)\n",
    "    pool =df[df.keys()[0]]\n",
    "    for key in pool.keys():\n",
    "        kernel_name = key\n",
    "        for i in range(len(pool[key])):\n",
    "            pool_function = pool[key][i][\"pool_function\"]\n",
    "            input_layout = pool[key][i][\"input\"][\"layout\"]\n",
    "            input_shape = pool[key][i][\"input\"][\"shape\"]\n",
    "            input_datatype = pool[key][i][\"input\"][\"datatype\"]\n",
    "            input_flag = pool[key][i][\"input\"][\"flag\"]\n",
    "\n",
    "            filter_shape =  pool[key][i][\"filter\"][\"shape\"]\n",
    "            filter_stride =  pool[key][i][\"filter\"][\"stride\"]\n",
    "            filter_padding =  pool[key][i][\"filter\"][\"padding\"]\n",
    "\n",
    "            output_layout = pool[key][i][\"output\"][\"layout\"]\n",
    "            output_shape = pool[key][i][\"output\"][\"shape\"]\n",
    "            output_datatype = pool[key][i][\"output\"][\"datatype\"]\n",
    "            output_flag = pool[key][i][\"output\"][\"flag\"]\n",
    "\n",
    "            writer.writerow([basename, kernel_name, pool_function,\n",
    "                             input_layout, input_shape[0], input_shape[1], input_shape[2], input_shape[3],input_datatype, input_flag, \\\n",
    "                                filter_shape[0],filter_shape[1], filter_stride[0],filter_stride[1], filter_padding,\\\n",
    "                                output_layout, output_shape[0], output_shape[1], output_shape[2], output_shape[3],output_datatype, output_flag ])\n",
    "    \n",
    "csvf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_up_next_multiple(n,m):\n",
    "    return ((n + m - 1) / m) * m\n",
    "\n",
    "values = \"-0.125488;0.279785;-0.343994;-0.166260;-0.479492;0.438477;-0.316650;-0.492920;0.111877;0.473877;0.285156;0.483154;0.107544;-0.486816;0.308350;-0.269043;-0.377930;-0.326660;0.162476;-0.291992;0.469482;-0.104858;0.421875;0.020828;-0.111328;0.086731;0.042694;-0.334717;0.272217;-0.485840;0.229004;0.426270;0.363037;-0.404541;-0.174805;-0.225220;-0.380371;0.221680;-0.006203;-0.389160;-0.468506;0.063293;-0.250732;-0.296875;-0.210205;0.124329;0.371582;-0.083496;0.307373;0.406738;-0.072876;-0.195190;-0.082581;-0.230591;-0.176758;-0.096191;0.462402;0.212280;-0.463135;-0.088989;0.408203;0.030930;-0.258057;-0.130371;-0.132202;-0.101196;0.335205;0.195801;0.177612;0.309570;-0.325684;0.017746;-0.158936;0.041443;0.160034;0.016632;-0.406982;0.382568;-0.150757;0.356445;0.296631;0.098633;-0.400146;0.101135;-0.443604;-0.287598;0.117493;-0.068054;-0.100159;-0.133667;0.118408;0.092407;0.180298;0.448975;-0.114563;0.184204;0.109985;0.409424;0.255371;0.046722;0.342285;0.394775;-0.173462;-0.454834;0.247314;-0.143188;-0.223999;-0.425537;-0.105103;0.315430;0.290283;-0.141479;0.350098;-0.436523;0.165894;0.387207;0.471680;0.061279;-0.459473;-0.474609;0.395752;0.008568;0.104431;-0.271240;0.194824;0.308105;-0.043457;0.392578;-0.377930;-0.389893;-0.499512;-0.493164;-0.015167;-0.162354;-0.281250;-0.136353;-0.253174;-0.199097;-0.233276;-0.448486;0.134399;-0.010544;0.092712;-0.262451;-0.029694;0.035767;-0.349365;-0.459229;-0.279785;-0.273438;0.440430;0.436768;0.235229;0.377441;-0.324951;0.029648;0.465332;0.133057;0.200317;0.387207;0.450684;0.096863;-0.441895;-0.357178;0.469971;-0.499268;-0.195801;-0.477051;-0.360596;-0.267334;-0.300293;-0.033234;-0.329590;0.442139;-0.195435;-0.259033;-0.004822;-0.108948;-0.188232;0.067688;0.275146;0.426758;-0.411621;0.461182;-0.228638;0.465332;-0.359131;-0.484375;-0.301270;-0.301270;0.271240;0.151123;0.123291;-0.129150;0.229614;0.061249;0.213257;-0.263916;0.022736;-0.060669;0.136353;0.195557;-0.089600;0.442871;-0.338867;-0.204346;0.303711;0.383301;0.395996;-0.227905;0.318115;-0.335449;-0.277832;-0.255859;0.018784;-0.435059;-0.248169;-0.351807;0.109558;-0.467041;-0.260498;-0.052216;0.172119;-0.257812;0.132324;0.316406;-0.179199;0.358398;-0.483398;-0.151367;0.190918;0.337646;-0.386475;0.195801;0.317139;-0.239136;0.397217;-0.311279;0.225952;-0.095520;-0.316650;-0.343994;-0.040741;0.208130;0.222046;-0.318115;0.111633;-0.208740;-0.453369;-0.043915;-0.117554;-0.453613;-0.049500;0.465576;-0.484131;-0.059845;0.333252;-0.241211;-0.074829;-0.315186;-0.050232;0.097900;0.070435;-0.174683;0.039703;-0.219116;-0.203735;0.486816;-0.206543;0.206909;0.105957;-0.384033;-0.050537;-0.188965;0.091309;-0.027786;0.348877;0.270996;0.210693;-0.392090;-0.024628;0.407471;0.039856;-0.423096;0.380371;0.133423;-0.281494;0.039337;-0.143677;-0.271973;-0.147461;0.010750;0.192383;0.442871;0.058105;0.471680;0.196289;-0.215210;0.476562;-0.221313;0.180664;0.485596;-0.419189;0.228271;0.483398;-0.409668;0.008202;0.090881;0.211182;0.145142;-0.102417;-0.362549;-0.291016;-0.242065;0.482178;-0.258057;0.058289;-0.161011;0.346680;0.279785;0.231934;-0.054169;0.366211;0.150879;0.332520;0.492188;0.024750;0.024780;-0.207886;-0.409424;0.014236;0.359863;-0.435059;0.063293;-0.402344;0.183228;-0.465576;-0.317871;0.020065;-0.468750;0.439453;0.227295;-0.303955;0.344482;0.328857;0.107056;0.302246;-0.076599;-0.494385;0.211304;-0.426025;0.415039;-0.169067;0.168823;0.137573;-0.117065;0.260742;-0.243896;-0.072449;-0.298340;-0.185669;-0.360596;0.255615;0.098877;0.429688;-0.394531;-0.313477;-0.175659;-0.182007;0.147705;0.360840;0.034088;-0.380127;-0.331787;0.203003;-0.246094;-0.002752;0.497803;0.002680;-0.154907;-0.355225;0.052887;0.261719;0.303223;0.133545;0.298340;-0.313477;-0.174072;0.012093;-0.403809;-0.113281;0.175659;0.424805;-0.271484;0.055206;0.496338;0.400391;-0.221069;0.397217;0.387695;0.279785;-0.343994;-0.166260;-0.479492;0.438477;-0.316650;-0.492920;0.111877;0.473877;0.285156;0.483154;0.107544;-0.486816;0.308350;-0.269043;-0.377930;-0.326660;0.162476;-0.291992;0.469482;-0.104858;0.421875;0.020828;-0.111328;0.086731;0.042694;-0.334717;0.272217;-0.485840;0.229004;0.426270;0.363037;-0.404541;-0.174805;-0.225220;-0.380371;0.221680;-0.006203;-0.389160;-0.468506;0.063293;-0.250732;-0.296875;-0.210205;0.124329;0.371582;-0.083496;0.307373;0.406738;-0.072876;-0.195190;-0.082581;-0.230591;-0.176758;-0.096191;0.462402;0.212280;-0.463135;-0.088989;0.408203;0.030930;-0.258057;-0.130371;-0.132202;-0.101196;0.335205;0.195801;0.177612;0.309570;-0.325684;0.017746;-0.158936;0.041443;0.160034;0.016632;-0.406982;0.382568;-0.150757;0.356445;0.142090;0.098633;-0.400146;0.101135;-0.443604;-0.287598;0.117493;-0.068054;-0.100159;-0.133667;0.118408;0.092407;0.180298;0.448975;-0.114563;0.184204;0.109985;0.409424;0.255371;0.046722;0.342285;0.394775;-0.173462;-0.454834;0.247314;-0.143188;-0.223999;-0.425537;-0.105103;0.315430;0.290283;-0.141479;0.350098;-0.436523;0.165894;0.387207;0.471680;0.061279;-0.459473;-0.474609;0.395752;0.008568;0.104431;-0.271240;0.194824;0.308105;-0.043457;0.392578;-0.377930;-0.389893;-0.499512;-0.493164;-0.015167;-0.162354;-0.281250;-0.136353;-0.253174;-0.199097;-0.233276;-0.448486;0.134399;-0.010544;0.092712;-0.262451;-0.029694;0.035767;-0.349365;-0.459229;-0.279785;-0.273438;0.440430;0.436768;0.235229;0.377441;-0.324951;0.029648;0.465332;0.133057;0.200317;0.387207;0.350830;0.096863;-0.441895;-0.357178;0.469971;-0.499268;-0.195801;-0.477051;-0.360596;-0.267334;-0.300293;-0.033234;-0.329590;0.442139;-0.195435;-0.259033;-0.004822;-0.108948;-0.188232;0.067688;0.275146;0.426758;-0.411621;0.461182;-0.228638;0.465332;-0.359131;-0.484375;-0.301270;-0.301270;0.271240;0.151123;0.123291;-0.129150;0.229614;0.061249;0.213257;-0.263916;0.022736;-0.060669;0.136353;0.195557;-0.089600;0.442871;-0.338867;-0.204346;0.303711;0.383301;0.395996;-0.227905;0.318115;-0.335449;-0.277832;-0.255859;0.018784;-0.435059;-0.248169;-0.351807;0.109558;-0.467041;-0.260498;-0.052216;0.172119;-0.257812;0.132324;0.316406;-0.179199;0.358398;-0.483398;-0.151367;0.190918;0.337646;-0.386475;0.195801;0.317139;-0.239136;0.397217;-0.311279;0.225952;-0.095520;-0.415771\"\n",
    "values_list = [float(i) for i in values.split(\";\")]\n",
    "print(len(values_list[::5]))\n",
    "print(values_list[::5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract PIX info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "rootpath = r\"C:\\Users\\GAME\\Documents\\Project\"\n",
    "log_file = \"PIX_log.txt\"\n",
    "file = os.path.join(rootpath, log_file)\n",
    "file = file.strip(\".txt\")\n",
    "rawdata = pd.read_csv(f\"{file}.txt\",delimiter = '\\t')\n",
    "\n",
    "signal_count = 0\n",
    "first_iteration_start = 0\n",
    "second_iteration_start = 0  \n",
    "## Option 1:\n",
    "#  use \"DML_EXECUTION_PLAN\" to find where is the start of first_iteration and second iteration\n",
    "#  value = line number - 1\n",
    "#  \n",
    "## Option 2:\n",
    "#  use the algorithm below to find first iteration and second iteration\n",
    "#  but mostly the time it does not work\n",
    "'''\n",
    "for index, line in rawdata.iterrows():\n",
    "    if signal_count == 5:\n",
    "        first_iteration = index\n",
    "    if signal_count == 10:\n",
    "        second_iteration = index\n",
    "        break\n",
    "    if \"Signal\" in line :\n",
    "        signal_count +=0\n",
    "'''\n",
    "## Option 3: [todo] use the whole information to decide\n",
    "\n",
    "first_iteration_start = 180\n",
    "second_iteration_start = 960\n",
    "prevline = \"\"\n",
    "ex_operator_list=[]\n",
    "ex_time = []\n",
    "\n",
    "dispatch_operator_list=[]\n",
    "dispatch_time=[]\n",
    "\n",
    "pre_checkDispatch =False\n",
    "idx = -1\n",
    "while idx < len(rawdata)-2: \n",
    "    idx+=1\n",
    "    if idx < first_iteration_start:\n",
    "        continue\n",
    "    if idx > second_iteration_start:\n",
    "        break\n",
    "    line = rawdata.iloc[idx]\n",
    "    if \"ExecuteMetaCommand\" in line[2]:      \n",
    "        ex_operator_list.append((prevline[2].strip()))\n",
    "        ex_time.append(int(prevline[4]))\n",
    "        # temp.append(line)\n",
    "    if \"Dispatch\" in line[2]:\n",
    "        if pre_checkDispatch:\n",
    "            continue\n",
    "        dispatch_operator_list.append((prevline[2].strip()))\n",
    "        dispatch_time.append(int(prevline[4]))\n",
    "        pre_checkDispatch = True \n",
    "    else:\n",
    "        prevline = line\n",
    "        pre_checkDispatch = False\n",
    "\n",
    "sumup= (sum(dispatch_time) + sum(ex_time))/1000000\n",
    "print(\"total latency per iteration: {} ms \\n \\\n",
    "      Tip: if the data is too different from ort_perf_test.exe,\\n \\\n",
    "      please double check the first/second iteration number\".format(round(sumup,2)))\n",
    "\n",
    "\n",
    "csv_file = f\"{file}_test.csv\"\n",
    "csvf = open(csv_file,\"w\",newline='')\n",
    "writer = csv.writer(csvf)\n",
    "line = [\"execute type\",\"layer type\",\"layer name\",\"time\"]\n",
    "writer.writerow(line)\n",
    "\n",
    "for op,time in zip(ex_operator_list,ex_time):\n",
    "    layer_info = op.split(\",\")[-1]\n",
    "    mark_idx = layer_info.index(\"(\")\n",
    "    layer_type = layer_info[0:mark_idx-1]\n",
    "    layer_name = layer_info[mark_idx+1:-1]\n",
    "    writer.writerow([\"ExecuteMetaCommand\",layer_type, layer_name,round(float(time)/1000000,2)])\n",
    "\n",
    "for op,time in zip(dispatch_operator_list,dispatch_time):\n",
    "    layer_info = op.split(\",\")[-1]\n",
    "    mark_idx = layer_info.index(\"(\")\n",
    "    layer_type = layer_info[0:mark_idx-1]\n",
    "    layer_name = layer_info[mark_idx+1:-1]\n",
    "    writer.writerow([\"Dispatch\",layer_type, layer_name,round(float(time)/1000000,2)])\n",
    "\n",
    "\n",
    "csvf.close()\n",
    "print(\"{} generated\".format(csv_file))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract info from benchmark.bat log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DML backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file = \"dml_log_release.txt\"\n",
    "csv_file = \"dml_perf_release.csv\"\n",
    "csvf = open(csv_file,\"w\",newline='')\n",
    "writer = csv.writer(csvf)\n",
    "line = [\"model name\",\"not save model\",\"save model\"]\n",
    "writer.writerow(line)\n",
    "with open(log_file,\"r\") as f:\n",
    "    all_lines = f.readlines()\n",
    "    idx = 0\n",
    "    while idx < len(all_lines):\n",
    "        line = all_lines[idx]\n",
    "        if \"model_rename\" in line:\n",
    "            model_name = line.rstrip().split(\"model_rename\\\\\")[-1]\n",
    "            if \"Average inference\" not in all_lines[idx+6]:\n",
    "                perf_save = all_lines[idx+10].rstrip().split(\"time cost:\")[-1]  \n",
    "                writer.writerow([model_name, \"erro\", perf_save])\n",
    "                idx = idx + 25\n",
    "                print(idx)\n",
    "            else:\n",
    "                perf_nosave = all_lines[idx+6].rstrip().split(\"time cost:\")[-1]   \n",
    "                perf_save = all_lines[idx+26].rstrip().split(\"time cost:\")[-1]\n",
    "                writer.writerow( [model_name , perf_nosave, perf_save])\n",
    "                idx = idx+41\n",
    "csvf.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenVINO backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file = \"ov_log.txt\"\n",
    "csv_file = \"ov_perf.csv\"\n",
    "csvf = open(csv_file,\"w\",newline='')\n",
    "writer = csv.writer(csvf)\n",
    "line = [\"model name\",\"FP16\",\"FP32\"]\n",
    "writer.writerow(line)\n",
    "with open(log_file,\"r\") as f:\n",
    "    all_lines = f.readlines()\n",
    "    idx = 0\n",
    "    while idx < len(all_lines):\n",
    "        line = all_lines[idx]\n",
    "        if \"model_rename\" in line:\n",
    "            model_name = line.rstrip().split(\"model_rename\\\\\")[-1]\n",
    "            print(model_name)\n",
    "            if \"time cost\" not in all_lines[idx+6]:\n",
    "                perf_save = all_lines[idx+7].rstrip().split(\"time cost:\")[-1]  \n",
    "                writer.writerow([model_name, \"erro\", perf_save])\n",
    "                idx = idx + 22\n",
    "            else:\n",
    "                perf_nosave = all_lines[idx+6].rstrip().split(\"time cost:\")[-1]   \n",
    "                perf_save = all_lines[idx+26].rstrip().split(\"time cost:\")[-1]\n",
    "                writer.writerow( [model_name , perf_nosave, perf_save])\n",
    "                idx = idx+41\n",
    "csvf.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract OV performance data\n",
    "## Option 1 if you have ort_perf_test.exe debug version:\n",
    "1. set `ORT_OPENVINO_ENABLE_DEBUG=1`, and run `ort_perf_test.exe  -m times -r 1 -I -e openvino -i \"device_type|GPU_FP32 cache_dir|ov_cache\" onnx_model_path`\n",
    "2. some performance logs will be appeared in the command window, here is an example below. You need to manually save it and process into csv file [The script below is some reference but it is not very good]\n",
    "```\n",
    "convolution10/WithoutBiases   EXECUTED       layerType: Convolution        realTime: 374       cpu: 0               execType: jit:ir__f16\n",
    "convolution10                 OPTIMIZED_OUT  layerType: Add                realTime: 0         cpu: 0               execType: undef\n",
    "activation10                  OPTIMIZED_OUT  layerType: Relu               realTime: 0         cpu: 0               execType: undef\n",
    "convolution11/WithoutBiases   EXECUTED       layerType: Convolution        realTime: 330       cpu: 0               execType: jit:ir__f16\n",
    "convolution11                 OPTIMIZED_OUT  layerType: Add                realTime: 0         cpu: 0               execType: undef\n",
    "activation11                  OPTIMIZED_OUT  layerType: Relu               realTime: 0         cpu: 0               execType: undef\n",
    "convolution12/WithoutBiases   EXECUTED       layerType: Convolution        realTime: 294       cpu: 0               execType: jit:ir__f16\n",
    "convolution12                 OPTIMIZED_OUT  layerType: Add                realTime: 0         cpu: 0               execType: undef\n",
    "activation12                  OPTIMIZED_OUT  layerType: Relu               realTime: 0         cpu: 0               execType: undef\n",
    "```\n",
    "3. The parsed onnx model will also be saved as `OpenVINOExecutionProvider_OpenVINO-EP-subgraph_1_0.onnx`, you can use this model to run `openvino benchmark_app` if the original model cannot be parsed by openvino\n",
    "\n",
    "## Option 2\n",
    "1. set python environment: pip install openvino_dev\n",
    "2. this package contains a tool called benchmark_app\n",
    "3. run benchmark_app with the command line\n",
    "`benchmark_app -m your_onnx_model_path -d GPU -nireq 1 -niter 10 --report_type detailed_counters --report_folder perf\\`\n",
    "4. after running this, a performance csv file will be generated under `perf\\` folder\n",
    "\n",
    "\n",
    "> I think the performance result in Option2 is validated for profiling ORT_OV performance because  I have checked the pipeline in onnxruntime ov. From my understanding, ort only did some work about parsing onnx model and rest of the works are all handled by OV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_file = r\"C:\\Users\\GAME\\Documents\\Project\\Adobe\\analyze\\Adobe-Ps_SuperZoom_V316.ov.txt\"\n",
    "csv_file = perf_file.replace(\"txt\",'csv')\n",
    "csvf = open(csv_file,\"w\",newline='')\n",
    "writer = csv.writer(csvf)\n",
    "line = [\"layer_type\",\"layer name\",\"gpu(ms)\",\"cpu(ms)\"]\n",
    "writer.writerow(line)\n",
    "total_time = 0\n",
    "with open(perf_file, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        line_items = line.rstrip().split(\" \")\n",
    "        info = [i for i in line_items if i != '']\n",
    "        #print(info)\n",
    "        layer_type = info[3]\n",
    "        layer_name = info[0]\n",
    "        gpu_time = int(info[5])/1000\n",
    "        cpu_time = int(info[7])/1000\n",
    "        total_time+=gpu_time\n",
    "        if gpu_time == 0.0:\n",
    "            continue\n",
    "        writer.writerow([layer_type,layer_name, gpu_time,cpu_time])\n",
    "print(\"total time: {:2f}\".format(total_time)) \n",
    "csvf.close()     "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract info from ORT profiling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ORT time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_file = r'C:\\Users\\GAME\\Documents\\Project\\AIGC\\perf\\unet_time_all.json'\n",
    "csv_file = time_file.replace(\"json\", 'csv')\n",
    "csvf = open(csv_file,\"w\",newline='')\n",
    "writer = csv.writer(csvf)\n",
    "line = [\"start\",\"duration\",\"name\",\"op_name\", \"provider\", \"role\", \"data_type\"]\n",
    "writer.writerow(line)\n",
    "with open(time_file, 'r') as f:\n",
    "    # load the contents of the file into a dictionary\n",
    "    data = json.load(f)\n",
    "    for i in range(len(data)):\n",
    "        temp = \"\"\n",
    "        if \"op_name\" not in data[i][\"args\"]:\n",
    "            continue\n",
    "        if \"provider\" not in data[i][\"args\"]:\n",
    "            temp = \"none\"\n",
    "            data_type = \"none\"\n",
    "            line = [data[i][\"ts\"],data[i][\"dur\"],data[i][\"name\"],data[i][\"args\"][\"op_name\"], temp, \"none\", data_type]\n",
    "            writer.writerow(line)\n",
    "        else:\n",
    "            temp = data[i][\"args\"][\"provider\"]\n",
    "            inputs = data[i][\"args\"][\"input_type_shape\"]\n",
    "            outputs = data[i][\"args\"][\"output_type_shape\"]\n",
    "            for input in inputs:\n",
    "                for key in input.keys():\n",
    "                    line = [data[i][\"ts\"],data[i][\"dur\"],data[i][\"name\"],data[i][\"args\"][\"op_name\"], temp, \"input\", key]\n",
    "                    writer.writerow(line)\n",
    "            for output in outputs:\n",
    "                for key in output.keys():\n",
    "                    line = [data[i][\"ts\"],data[i][\"dur\"],data[i][\"name\"],data[i][\"args\"][\"op_name\"], temp, \"output\", key]\n",
    "                    writer.writerow(line)\n",
    "        #print(line)\n",
    "        \n",
    "        \n",
    "csvf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get shape\n",
    "# index value in profile is same with allocator_planner.cc\n",
    "# index value in tensor allocation is different, where is it?\n",
    "time_file = r'C:\\Users\\GAME\\Documents\\Project\\onnxruntime\\build\\Windows\\Debug\\Debug\\file_small.log_2023-06-20_15-08-04.json'\n",
    "csv_file = time_file.replace(\"json\", 'csv')\n",
    "csvf = open(csv_file,\"w\",newline='')\n",
    "writer = csv.writer(csvf)\n",
    "line = [\"name\",\"op_type\",\"output_size\",\"output_shape\"]\n",
    "writer.writerow(line)\n",
    "count = 0\n",
    "node_count =0\n",
    "with open(time_file, 'r') as f:\n",
    "    # load the contents of the file into a dictionary\n",
    "    data = json.load(f)\n",
    "    for i in range(len(data)):\n",
    "        if \"/conv_in/Conv_fence_before\" in data[i][\"name\"]:\n",
    "            count += 1\n",
    "        if count == 2:\n",
    "            break\n",
    "        if \"kernel\" in data[i][\"name\"]:\n",
    "           \n",
    "            output_name = data[i][\"name\"].split(\"_kernel\")[0]\n",
    "            op_type = data[i]['args']['op_name']\n",
    "            #print(output_name)\n",
    "            output_size = data[i]['args']['output_size']\n",
    "            #print(data[i]['args']['input_type_shape'])\n",
    "            if \"float16\" in data[i]['args']['output_type_shape'][0].keys():\n",
    "                output_shape = data[i]['args']['output_type_shape'][0][\"float16\"] # only one output\n",
    "            else:\n",
    "                continue\n",
    "            # if \"int64\" in data[i]['args']['output_type_shape'][0].keys():\n",
    "            #     output_shape = data[i]['args']['output_type_shape'][0][\"int64\"]\n",
    "            newline = [output_name, op_type, output_size,output_shape]\n",
    "            writer.writerow(newline)\n",
    "            node_count+=1\n",
    "print(node_count)\n",
    "csvf.close()\n",
    "          \n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ORT memroy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_file = r\"C:\\Users\\GAME\\Documents\\Project\\AIGC\\perf\\unet_mem_all.txt\"\n",
    "csv_file = mem_file.replace(\"txt\", 'csv')\n",
    "\n",
    "csvf = open(csv_file,\"w\",newline='')\n",
    "writer = csv.writer(csvf)\n",
    "line = [\"Tensor name\",\"op_type\",\"Index\",\"Reuse inplace\",\"Reused Node index\",\"Alloc type\",\"Device type\",\"Memory type\",\"Device id\", \"lifetime start\",\"lifetime end\", \"planned block start\",\"planned block end\",\"planned size\", \"allocated block start\",\"allocated block end\", \"allocated size\"]\n",
    "writer.writerow(line)\n",
    "init_count = 0\n",
    "with open(mem_file,'r') as f:\n",
    "    for line in f.readlines():\n",
    "        if \"Initializer in Device\" in line:\n",
    "            init_count += 1        \n",
    "        if init_count == 3:\n",
    "            break\n",
    "        if \"Tensor name\" not in line:\n",
    "            continue\n",
    "        tensor_name = line.split(\"Tensor name: \")[1].split(\", Index\")[0].strip()\n",
    "      \n",
    "        index = line.split(\"Index: \")[1].split(\", Reuse inplace\")[0].strip()\n",
    "        reuse = line.split(\"Reuse inplace: \")[1].split(\", Reused Node index\")[0].strip()\n",
    "        reuse_index = line.split(\"Reused Node index: \")[1].split(\", Alloc type\")[0].strip()\n",
    "        alloc_type= line.split(\"Alloc type: \")[1].split(\", Location\")[0].strip()\n",
    "        if alloc_type ==\"AllocateStatically\":\n",
    "            op_type = \"\"\n",
    "        else:\n",
    "            op_type = tensor_name.split(\"/\")[-1].split(\"_\")[0] # this op is still incorrect\n",
    "        location = line.split(\"Location: \")[1].split(\", lifetime\")[0].strip()\n",
    "        device_type = location.split(\"DeviceType:\")[1].split(\"MemoryType\")[0].strip()\n",
    "        memory_type = location.split(\"MemoryType:\")[1].split(\"DeviceId\")[0].strip()\n",
    "        device_id = location.split(\"DeviceId:\")[1].split(\"]\")[0].strip()\n",
    "        \n",
    "        lt_start = line.split(\"lifetime: (\")[1].split(\",\")[0].strip()\n",
    "        lt_end = line.split(\"lifetime: (\")[1].split(\",\")[1].split(\")\")[0].strip()\n",
    "        pb_start = line.split(\"planned block: (\")[1].split(\",\")[0].strip()\n",
    "        pb_end = line.split(\"planned block: (\")[1].split(\",\")[1].split(\")\")[0].strip()\n",
    "        pb_size = line.split(\"planned size: \")[1].split(\", allocated block\")[0].strip()\n",
    "        ab_start = line.split(\"allocated block: (\")[1].split(\",\")[0].strip()\n",
    "        ab_end = line.split(\"allocated block: (\")[1].split(\",\")[1].split(\")\")[0].strip()\n",
    "        ab_size = line.split(\"allocated size: \")[1].strip()\n",
    "        newline = [tensor_name,op_type,index,reuse,reuse_index,alloc_type,device_type,memory_type,device_id,lt_start,lt_end,pb_start,pb_end,pb_size, ab_start,ab_end,ab_size]\n",
    "       \n",
    "        # strings =[tensor_name,index,reuse,alloc_type,location,lt_start,lt_end,pb_start,pb_end,pb_size, ab_start,ab_end,ab_size]\n",
    "        # newline = \",\".join(strings)\n",
    "        writer.writerow(newline)\n",
    "csvf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time file is for node, cannot mapping with memory info(output tensor)\n",
    "# combine optimized_onnx_node with memory info\n",
    "onnx_csv = r'C:\\Users\\GAME\\Documents\\Project\\AIGC\\perf\\unet_optimized_onnx_node.csv'\n",
    "memory_csv = r'C:\\Users\\GAME\\Documents\\Project\\AIGC\\perf\\unet_mem_all.csv'\n",
    "new_csv = memory_csv.replace(\".csv\",\"_new.csv\")\n",
    "csvf = open(new_csv,\"w\",newline='')\n",
    "writer = csv.writer(csvf)\n",
    "count = 0\n",
    "with open(memory_csv, 'r') as mem_file:\n",
    "    reader = csv.reader(mem_file)\n",
    "    for i, mem_row in enumerate(reader):\n",
    "        if i == 0:\n",
    "            mem_row.append(\"op_type\")\n",
    "            #mem_row.append(\"shape\")\n",
    "            writer.writerow(mem_row)\n",
    "            continue\n",
    "\n",
    "        with open(onnx_csv, 'r') as onnx_file:\n",
    "            reader2 = csv.reader(onnx_file)\n",
    "            for j, row in enumerate(reader2):\n",
    "                if j ==0:\n",
    "                    continue\n",
    "                if row[2]==\"output\" and row[3] == mem_row[0]:\n",
    "                    mem_row.append(row[1])\n",
    "                    #mem_row.append(row[2])\n",
    "                    count+=1\n",
    "                    break\n",
    "                # if j == 921 and mem_row[4] != \"AllocateStatically\":\n",
    "                #     pass\n",
    "                    #print(mem_row[0],mem_row[-1], row[0],row[2])\n",
    "        writer.writerow(mem_row)\n",
    "csvf.close()\n",
    "print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare uent_time_all.csv with dml_node.csv\n",
    "time_csv = r'C:\\Users\\GAME\\Documents\\Project\\AIGC\\perf\\dynamic_dim\\unet_time_all.csv'\n",
    "dml_csv = r'C:\\Users\\GAME\\Documents\\Project\\AIGC\\perf\\unet_dml_node.csv'\n",
    "\n",
    "node_set =set()\n",
    "\n",
    "# row_count = sum(1 for row in dmlreader)\n",
    "count = 0\n",
    "total_memory_size = 0\n",
    "max_memory_size = 0\n",
    "with open(time_csv, 'r') as timef:\n",
    "    reader = csv.reader(timef)\n",
    "    for i, row in enumerate(reader):\n",
    "        if i==0 or len(row) == 0:\n",
    "            continue\n",
    "        node_set.add(row[0])\n",
    "        with open(dml_csv, 'r') as dmlf:\n",
    "            dmlreader = csv.reader(dmlf)\n",
    "            for j, dmlrow in enumerate(dmlreader):\n",
    "                if j==0 or len(dmlrow) ==0:\n",
    "                    continue\n",
    "                if row[0] == dmlrow[0]:\n",
    "                    count+=1\n",
    "                    shape = row[3].split(\",\")\n",
    "                    if len(shape) == 1:\n",
    "                        continue\n",
    "                    memory_size = 1\n",
    "                    for v in shape:\n",
    "                        if \"[\" in v:\n",
    "                            v_int = int(v.split(\"[\")[-1].strip())\n",
    "                        else:\n",
    "                            if \"]\" in v:\n",
    "                                v_int = int(v.split(\"]\")[0].strip())\n",
    "                            else:\n",
    "                                v_int = int(v.strip())\n",
    "                        memory_size *=v_int\n",
    "                    #print(memory_size)\n",
    "                    total_memory_size+=memory_size\n",
    "                    max_memory_size = max_memory_size if max_memory_size > memory_size else memory_size\n",
    "                    break\n",
    "                if j == 920:                   \n",
    "                    print(row[0], dmlrow[0])\n",
    "print(len(node_set)-count)\n",
    "print(total_memory_size*2/1000000000)\n",
    "print(max_memory_size*2/1000000000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miscellaneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_size(node_name, filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        # load the contents of the file into a dictionary\n",
    "        data = json.load(f)\n",
    "        max_size = 0\n",
    "        for i in range(len(data)):\n",
    "            if \"provider\" not in data[i][\"args\"]:\n",
    "                continue\n",
    "            provider = data[i][\"args\"][\"provider\"]\n",
    "            op_name = data[i][\"args\"][\"op_name\"]\n",
    "            if provider !=\"DmlExecutionProvider\":\n",
    "                continue\n",
    "                # for value in data[i][\"args\"][\"input_type_shape\"]:\n",
    "                #     if \"float\" in value:\n",
    "                #         print(data[i][\"name\"], value)\n",
    "            if node_name in op_name:\n",
    "                for value in data[i][\"args\"][\"input_type_shape\"]:\n",
    "                    if \"float16\" in value: # float16 = 2B\n",
    "\n",
    "                        x_shape = np.array(value[\"float16\"])\n",
    "                        temp_size = np.prod(x_shape)#[0]*x_shape[1]*x_shape[2]        \n",
    "                        if max_size < temp_size:\n",
    "                            max_size =  temp_size\n",
    "                            kernel_name = data[i][\"name\"]\n",
    "    print(max_size)\n",
    "    print(kernel_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = r'C:\\Users\\GAME\\Documents\\Project\\AIGC\\perf\\onnxruntime_profile__unet_1.5_olive.json'\n",
    "#get_max_size(\"LayerNormalization\")\n",
    "#get_max_size(\"InstanceNormalization\")\n",
    "get_max_size(\"MatMul\",filename)\n",
    "#get_max_size(\"Mul\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time(provider,op, path):\n",
    "    total_time = 0\n",
    "    provider_time = 0\n",
    "    ops_time = {}\n",
    "    with open(path, 'r') as f:\n",
    "        # load the contents of the file into a dictionary\n",
    "        data = json.load(f)\n",
    "        for i in range(len(data)):\n",
    "            if \"op_name\" not in data[i][\"args\"]:\n",
    "                continue\n",
    "            op_name = data[i][\"args\"][\"op_name\"]               \n",
    "            duration = int(data[i][\"dur\"])\n",
    "            total_time +=duration\n",
    "            if \"provider\" in data[i][\"args\"]:\n",
    "                provider_name = data[i][\"args\"][\"provider\"]\n",
    "                if provider == provider_name:\n",
    "                    if op == op_name or op == None:\n",
    "                        provider_time +=duration\n",
    "                        if \"DmlFusedNode\" in op_name:\n",
    "                            continue\n",
    "                        if op_name in ops_time:\n",
    "                            ops_time[op_name] += duration\n",
    "                        else:\n",
    "                            ops_time[op_name] = 0\n",
    "\n",
    "                        \n",
    "            \n",
    "    print(total_time)\n",
    "    print(ops_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\GAME\\Documents\\Project\\AIGC\\perf\\onnxruntime_profile__DG2_unet_1.5_olive.json'\n",
    "get_time(\"DmlExecutionProvider\",\"MemcpyFromHost\", path)\n",
    "get_time(\"DmlExecutionProvider\",\"MemcpyToHost\", path)\n",
    "get_time(\"DmlExecutionProvider\",None, path)\n",
    "get_time(\"CPUExecutionProvider\",None, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kernelname(provider, op,filename):\n",
    "    ops = set()\n",
    "    with open(path, 'r') as f:\n",
    "        # load the contents of the file into a dictionary\n",
    "        data = json.load(f)\n",
    "        for i in range(len(data)):\n",
    "            if \"op_name\" not in data[i][\"args\"]:\n",
    "                continue\n",
    "            op_name = data[i][\"args\"][\"op_name\"]               \n",
    "            if \"provider\" in data[i][\"args\"]:\n",
    "                provider_name = data[i][\"args\"][\"provider\"]\n",
    "                if provider == provider_name:\n",
    "                    if op == op_name or op == None:\n",
    "                        print(data[i]['name'])\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\GAME\\Documents\\Project\\AIGC\\perf\\onnxruntime_profile__DG2_unet_1.5_olive.json'\n",
    "get_kernelname(\"CPUExecutionProvider\",\"Mul\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_type(filename):\n",
    "    input_data_type = set()\n",
    "    output_data_type = set()\n",
    "    with open(filename, 'r') as f:\n",
    "        # load the contents of the file into a dictionary\n",
    "        data = json.load(f)\n",
    "        max_size = 0\n",
    "        for i in range(len(data)):\n",
    "            if \"provider\" not in data[i][\"args\"]:\n",
    "                continue\n",
    "            \n",
    "            inputs = data[i][\"args\"][\"input_type_shape\"]\n",
    "            outputs = data[i][\"args\"][\"output_type_shape\"]\n",
    "            for input in inputs:\n",
    "                for key in input.keys():\n",
    "                    input_data_type.add(key)\n",
    "            for output in outputs:\n",
    "                for key in output.keys():\n",
    "                    output_data_type.add(key)\n",
    "    print(input_data_type)\n",
    "    print(output_data_type)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\GAME\\Documents\\Project\\AIGC\\perf\\onnxruntime_profile__DG2_unet_1.5_olive.json'\n",
    "get_type(path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "analyze openvino model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "tree = ET.parse(r'..\\AIGC\\optimize\\unet_ov.xml')\n",
    "root = tree.getroot()\n",
    "for child in root:\n",
    "    if child.tag !=\"layers\":\n",
    "        continue\n",
    "    for subchild in child:\n",
    "        if \"FullyConnected\" == subchild.attrib[\"type\"]:\n",
    "            ports = subchild.find(\"input/port\")\n",
    "            if len(ports) == 2:\n",
    "                print(subchild.attrib[\"name\"])\n",
    "                break\n",
    "            # data_size = 1\n",
    "            # for value in ports.iter(\"dim\"):\n",
    "            #     data_size *= int(value.text)\n",
    "            # print(data_size)\n",
    "\n",
    "      \n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert onnx memory file into csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_file = r\"C:\\Users\\GAME\\Documents\\Project\\AIGC\\perf\\unet_mem_all.txt\"\n",
    "csv_file = mem_file.replace(\"txt\", 'csv')\n",
    "\n",
    "\n",
    "with open(mem_file,'r') as f:\n",
    "    for line in f.readlines():\n",
    "        if \"peak_rss\" not in line:\n",
    "            continue\n",
    "        print(line.rstrip())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze csv file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pandasForSortingCSV\n",
    "def get_graph_info(file_csv,idx):\n",
    "    # assign dataset\n",
    "    csvData = pandasForSortingCSV.read_csv(file_csv)\n",
    "    print(csvData.groupby(csvData.columns[idx]).sum() )\n",
    "                                         \n",
    "    # sort data frame\n",
    "    # csvData.sort_values(csvData.columns[1], \n",
    "    #                     axis=0,\n",
    "    #                     inplace=True)                    \n",
    "    \n",
    "    # # displaying sorted data frame\n",
    "    # print(\"\\nAfter sorting:\")\n",
    "    # print(csvData)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
